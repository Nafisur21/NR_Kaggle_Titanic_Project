{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nafisur Rahman\n",
    "nafisur21@gmail.com<br>\n",
    "https://www.linkedin.com/in/nafisur-rahman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survival\n",
    "Predict who survived the titanic disaster\n",
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About this project\n",
    "The Titanic dataset provides observations for each passenger and the survival outcome. The problem statement entails predicting whether a passenger would survive or not survive given the features such as passenger class, sex, fare, age, number of\n",
    "siblings/spouse aboard, number of parents/children aboard, and others.<br>\n",
    "The task is about understanding the Titanic Disaster with the help of Data Visualization and building a model that can predict the Survival of the Passengers of Titanic using Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Importing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import IPython\n",
    "from IPython import display\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Loading Processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_processed=pd.read_csv(\"Processed_data/train_processed.csv\",index_col='PassengerId')\n",
    "test_processed=pd.read_csv(\"Processed_data/test_processed.csv\",index_col='PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsMother</th>\n",
       "      <th>IsMale</th>\n",
       "      <th>Deck_A</th>\n",
       "      <th>Deck_B</th>\n",
       "      <th>Deck_C</th>\n",
       "      <th>Deck_D</th>\n",
       "      <th>Deck_E</th>\n",
       "      <th>Deck_F</th>\n",
       "      <th>Deck_G</th>\n",
       "      <th>Deck_Z</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Title_Lady</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Officer</th>\n",
       "      <th>Title_Sir</th>\n",
       "      <th>Fare_Bin_very_low</th>\n",
       "      <th>Fare_Bin_low</th>\n",
       "      <th>Fare_Bin_high</th>\n",
       "      <th>Fare_Bin_very_high</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>AgeState_Adult</th>\n",
       "      <th>AgeState_Child</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived   Age     Fare  FamilySize  IsMother  IsMale  Deck_A  \\\n",
       "PassengerId                                                                  \n",
       "1                   0  22.0   7.2500           2         0       1       0   \n",
       "2                   1  38.0  71.2833           2         0       0       0   \n",
       "3                   1  26.0   7.9250           1         0       0       0   \n",
       "4                   1  35.0  53.1000           2         0       0       0   \n",
       "5                   0  35.0   8.0500           1         0       1       0   \n",
       "\n",
       "             Deck_B  Deck_C  Deck_D  Deck_E  Deck_F  Deck_G  Deck_Z  Pclass_1  \\\n",
       "PassengerId                                                                     \n",
       "1                 0       0       0       0       0       0       1         0   \n",
       "2                 0       1       0       0       0       0       0         1   \n",
       "3                 0       0       0       0       0       0       1         0   \n",
       "4                 0       1       0       0       0       0       0         1   \n",
       "5                 0       0       0       0       0       0       1         0   \n",
       "\n",
       "             Pclass_2  Pclass_3  Title_Lady  Title_Master  Title_Miss  \\\n",
       "PassengerId                                                             \n",
       "1                   0         1           0             0           0   \n",
       "2                   0         0           0             0           0   \n",
       "3                   0         1           0             0           1   \n",
       "4                   0         0           0             0           0   \n",
       "5                   0         1           0             0           0   \n",
       "\n",
       "             Title_Mr  Title_Mrs  Title_Officer  Title_Sir  Fare_Bin_very_low  \\\n",
       "PassengerId                                                                     \n",
       "1                   1          0              0          0                  1   \n",
       "2                   0          1              0          0                  0   \n",
       "3                   0          0              0          0                  0   \n",
       "4                   0          1              0          0                  0   \n",
       "5                   1          0              0          0                  0   \n",
       "\n",
       "             Fare_Bin_low  Fare_Bin_high  Fare_Bin_very_high  Embarked_C  \\\n",
       "PassengerId                                                                \n",
       "1                       0              0                   0           0   \n",
       "2                       0              0                   1           1   \n",
       "3                       1              0                   0           0   \n",
       "4                       0              0                   1           0   \n",
       "5                       1              0                   0           0   \n",
       "\n",
       "             Embarked_Q  Embarked_S  AgeState_Adult  AgeState_Child  \n",
       "PassengerId                                                          \n",
       "1                     0           1               1               0  \n",
       "2                     0           0               1               0  \n",
       "3                     0           1               1               0  \n",
       "4                     0           1               1               0  \n",
       "5                     0           1               1               0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 33 columns):\n",
      "Survived              891 non-null int64\n",
      "Age                   891 non-null float64\n",
      "Fare                  891 non-null float64\n",
      "FamilySize            891 non-null int64\n",
      "IsMother              891 non-null int64\n",
      "IsMale                891 non-null int64\n",
      "Deck_A                891 non-null int64\n",
      "Deck_B                891 non-null int64\n",
      "Deck_C                891 non-null int64\n",
      "Deck_D                891 non-null int64\n",
      "Deck_E                891 non-null int64\n",
      "Deck_F                891 non-null int64\n",
      "Deck_G                891 non-null int64\n",
      "Deck_Z                891 non-null int64\n",
      "Pclass_1              891 non-null int64\n",
      "Pclass_2              891 non-null int64\n",
      "Pclass_3              891 non-null int64\n",
      "Title_Lady            891 non-null int64\n",
      "Title_Master          891 non-null int64\n",
      "Title_Miss            891 non-null int64\n",
      "Title_Mr              891 non-null int64\n",
      "Title_Mrs             891 non-null int64\n",
      "Title_Officer         891 non-null int64\n",
      "Title_Sir             891 non-null int64\n",
      "Fare_Bin_very_low     891 non-null int64\n",
      "Fare_Bin_low          891 non-null int64\n",
      "Fare_Bin_high         891 non-null int64\n",
      "Fare_Bin_very_high    891 non-null int64\n",
      "Embarked_C            891 non-null int64\n",
      "Embarked_Q            891 non-null int64\n",
      "Embarked_S            891 non-null int64\n",
      "AgeState_Adult        891 non-null int64\n",
      "AgeState_Child        891 non-null int64\n",
      "dtypes: float64(2), int64(31)\n",
      "memory usage: 236.7 KB\n"
     ]
    }
   ],
   "source": [
    "train_processed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsMother</th>\n",
       "      <th>IsMale</th>\n",
       "      <th>Deck_A</th>\n",
       "      <th>Deck_B</th>\n",
       "      <th>Deck_C</th>\n",
       "      <th>Deck_D</th>\n",
       "      <th>Deck_E</th>\n",
       "      <th>Deck_F</th>\n",
       "      <th>Deck_G</th>\n",
       "      <th>Deck_Z</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Title_Lady</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Officer</th>\n",
       "      <th>Title_Sir</th>\n",
       "      <th>Fare_Bin_very_low</th>\n",
       "      <th>Fare_Bin_low</th>\n",
       "      <th>Fare_Bin_high</th>\n",
       "      <th>Fare_Bin_very_high</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>AgeState_Adult</th>\n",
       "      <th>AgeState_Child</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>34.5</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>47.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>62.0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>27.0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>22.0</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age     Fare  FamilySize  IsMother  IsMale  Deck_A  Deck_B  \\\n",
       "PassengerId                                                                \n",
       "892          34.5   7.8292           1         0       1       0       0   \n",
       "893          47.0   7.0000           2         0       0       0       0   \n",
       "894          62.0   9.6875           1         0       1       0       0   \n",
       "895          27.0   8.6625           1         0       1       0       0   \n",
       "896          22.0  12.2875           3         1       0       0       0   \n",
       "\n",
       "             Deck_C  Deck_D  Deck_E  Deck_F  Deck_G  Deck_Z  Pclass_1  \\\n",
       "PassengerId                                                             \n",
       "892               0       0       0       0       0       1         0   \n",
       "893               0       0       0       0       0       1         0   \n",
       "894               0       0       0       0       0       1         0   \n",
       "895               0       0       0       0       0       1         0   \n",
       "896               0       0       0       0       0       1         0   \n",
       "\n",
       "             Pclass_2  Pclass_3  Title_Lady  Title_Master  Title_Miss  \\\n",
       "PassengerId                                                             \n",
       "892                 0         1           0             0           0   \n",
       "893                 0         1           0             0           0   \n",
       "894                 1         0           0             0           0   \n",
       "895                 0         1           0             0           0   \n",
       "896                 0         1           0             0           0   \n",
       "\n",
       "             Title_Mr  Title_Mrs  Title_Officer  Title_Sir  Fare_Bin_very_low  \\\n",
       "PassengerId                                                                     \n",
       "892                 1          0              0          0                  1   \n",
       "893                 0          1              0          0                  1   \n",
       "894                 1          0              0          0                  0   \n",
       "895                 1          0              0          0                  0   \n",
       "896                 0          1              0          0                  0   \n",
       "\n",
       "             Fare_Bin_low  Fare_Bin_high  Fare_Bin_very_high  Embarked_C  \\\n",
       "PassengerId                                                                \n",
       "892                     0              0                   0           0   \n",
       "893                     0              0                   0           0   \n",
       "894                     1              0                   0           0   \n",
       "895                     1              0                   0           0   \n",
       "896                     1              0                   0           0   \n",
       "\n",
       "             Embarked_Q  Embarked_S  AgeState_Adult  AgeState_Child  \n",
       "PassengerId                                                          \n",
       "892                   1           0               1               0  \n",
       "893                   0           1               1               0  \n",
       "894                   1           0               1               0  \n",
       "895                   0           1               1               0  \n",
       "896                   0           1               1               0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 418 entries, 892 to 1309\n",
      "Data columns (total 32 columns):\n",
      "Age                   418 non-null float64\n",
      "Fare                  418 non-null float64\n",
      "FamilySize            418 non-null int64\n",
      "IsMother              418 non-null int64\n",
      "IsMale                418 non-null int64\n",
      "Deck_A                418 non-null int64\n",
      "Deck_B                418 non-null int64\n",
      "Deck_C                418 non-null int64\n",
      "Deck_D                418 non-null int64\n",
      "Deck_E                418 non-null int64\n",
      "Deck_F                418 non-null int64\n",
      "Deck_G                418 non-null int64\n",
      "Deck_Z                418 non-null int64\n",
      "Pclass_1              418 non-null int64\n",
      "Pclass_2              418 non-null int64\n",
      "Pclass_3              418 non-null int64\n",
      "Title_Lady            418 non-null int64\n",
      "Title_Master          418 non-null int64\n",
      "Title_Miss            418 non-null int64\n",
      "Title_Mr              418 non-null int64\n",
      "Title_Mrs             418 non-null int64\n",
      "Title_Officer         418 non-null int64\n",
      "Title_Sir             418 non-null int64\n",
      "Fare_Bin_very_low     418 non-null int64\n",
      "Fare_Bin_low          418 non-null int64\n",
      "Fare_Bin_high         418 non-null int64\n",
      "Fare_Bin_very_high    418 non-null int64\n",
      "Embarked_C            418 non-null int64\n",
      "Embarked_Q            418 non-null int64\n",
      "Embarked_S            418 non-null int64\n",
      "AgeState_Adult        418 non-null int64\n",
      "AgeState_Child        418 non-null int64\n",
      "dtypes: float64(2), int64(30)\n",
      "memory usage: 107.8 KB\n"
     ]
    }
   ],
   "source": [
    "test_processed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Dataset in numpy ndarray format\n",
    "For doing machine learning analysis, we have to convert the DataFrame into numpy matrix of features and output column as numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_processed=train_processed.iloc[:,1:].values.astype('float')\n",
    "X_train_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_processed=train_processed.iloc[:,0].values\n",
    "y_train_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_processed=test_processed.iloc[:,0:].values.astype('float')\n",
    "X_test_processed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features Matrix X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 22.    ,   7.25  ,   2.    , ...,   1.    ,   1.    ,   0.    ],\n",
       "       [ 38.    ,  71.2833,   2.    , ...,   0.    ,   1.    ,   0.    ],\n",
       "       [ 26.    ,   7.925 ,   1.    , ...,   1.    ,   1.    ,   0.    ],\n",
       "       ..., \n",
       "       [ 22.    ,  23.45  ,   4.    , ...,   1.    ,   1.    ,   0.    ],\n",
       "       [ 26.    ,  30.    ,   1.    , ...,   0.    ,   1.    ,   0.    ],\n",
       "       [ 32.    ,   7.75  ,   1.    , ...,   0.    ,   1.    ,   0.    ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=X_train_processed\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output/Dependent Variable y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=y_train_processed\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Splitting data into Training and Test set\n",
    "We split the data into training and test sets using an 80/20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 32) (712,)\n",
      "(179, 32) (179,)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean survival in train : 0.383\n",
      "mean survival in test : 0.385\n"
     ]
    }
   ],
   "source": [
    "# average survival in train and test\n",
    "print('mean survival in train : {0:.3f}'.format(np.mean(y_train)))\n",
    "print('mean survival in test : {0:.3f}'.format(np.mean(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)\n",
    "X_test_processed_sc=sc.transform(X_test_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models\n",
    "1. Baseline Model\n",
    "2. Logistic Regression\n",
    "3. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Baseline Model: DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier as dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for baseline model : 0.614525139665\n",
      "confusion matrix for baseline model:\n",
      " [[110   0]\n",
      " [ 69   0]]\n",
      "F1 score for baseline model : 0.0\n",
      "Precision score for baseline model : 0.0\n",
      "recall score for baseline model : 0.0\n"
     ]
    }
   ],
   "source": [
    "model_dummy=dc(strategy='most_frequent',random_state=0)\n",
    "model_dummy.fit(X_train,y_train)\n",
    "y_pred_dummy=model_dummy.predict(X_test)\n",
    "print('accuracy for baseline model :',accuracy_score(y_test,y_pred_dummy))\n",
    "print('confusion matrix for baseline model:\\n',confusion_matrix(y_test,y_pred_dummy))\n",
    "print('F1 score for baseline model :',f1_score(y_test,y_pred_dummy))\n",
    "print('Precision score for baseline model :',precision_score(y_test,y_pred_dummy))\n",
    "print('recall score for baseline model :',recall_score(y_test,y_pred_dummy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_lr=lr(random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(model_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying Grid Search to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy : 0.827247191011\n",
      "Best parameters:\n",
      " {'C': 1.0, 'penalty': 'l1'}\n",
      "Wall time: 7.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'C':[0.5,1.0, 10.0, 50.0, 100.0, 1000.0], 'penalty' : ['l1','l2']}\n",
    "grid_search = GridSearchCV(estimator = model_lr,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train_sc, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print('Best Accuracy :',best_accuracy)\n",
    "print('Best parameters:\\n',best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for Logistic Regression : 0.843575418994\n",
      "confusion matrix for Logistic Regression:\n",
      " [[96 14]\n",
      " [14 55]]\n",
      "F1 score for Logistic Regression : 0.797101449275\n",
      "Precision score for Logistic Regression : 0.797101449275\n",
      "recall score for Logistic Regression : 0.797101449275\n",
      "Wall time: 52.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_lr=lr(penalty='l2',C=1.0,random_state=0)\n",
    "model_lr.fit(X_train_sc,y_train)\n",
    "y_pred_lr=model_lr.predict(X_test_sc)\n",
    "print('accuracy for Logistic Regression :',accuracy_score(y_test,y_pred_lr))\n",
    "print('confusion matrix for Logistic Regression:\\n',confusion_matrix(y_test,y_pred_lr))\n",
    "print('F1 score for Logistic Regression :',f1_score(y_test,y_pred_lr))\n",
    "print('Precision score for Logistic Regression :',precision_score(y_test,y_pred_lr))\n",
    "print('recall score for Logistic Regression :',recall_score(y_test,y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. K-Nearest Neighbors (K-NN) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_knn=knn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(model_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy : 0.818820224719\n",
      "Best parameters:\n",
      " {'algorithm': 'auto', 'leaf_size': 5, 'metric': 'minkowski', 'n_neighbors': 6, 'p': 1, 'weights': 'uniform'}\n",
      "Wall time: 15.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'n_neighbors':[5,6,7], 'weights' : ['uniform','distance'],'algorithm':['auto'],\n",
    "              'leaf_size':[5,10],'p':[1,2],'metric':['minkowski']}\n",
    "grid_search = GridSearchCV(estimator = model_knn,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train_sc, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print('Best Accuracy :',best_accuracy)\n",
    "print('Best parameters:\\n',best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for K-Nearest Neighbors Classifier : 0.849162011173\n",
      "confusion matrix for K-Nearest Neighbors Classifier:\n",
      " [[102   8]\n",
      " [ 19  50]]\n",
      "F1 score for K-Nearest Neighbors Classifier : 0.787401574803\n",
      "Precision score for K-Nearest Neighbors Classifier : 0.862068965517\n",
      "recall score for K-Nearest Neighbors Classifier : 0.724637681159\n",
      "Wall time: 68 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_knn=knn(algorithm='auto',leaf_size=10,metric='minkowski',n_neighbors=5,p=1,weights='uniform')\n",
    "model_knn.fit(X_train_sc,y_train)\n",
    "y_pred_knn=model_knn.predict(X_test_sc)\n",
    "print('accuracy for K-Nearest Neighbors Classifier :',accuracy_score(y_test,y_pred_knn))\n",
    "print('confusion matrix for K-Nearest Neighbors Classifier:\\n',confusion_matrix(y_test,y_pred_knn))\n",
    "print('F1 score for K-Nearest Neighbors Classifier :',f1_score(y_test,y_pred_knn))\n",
    "print('Precision score for K-Nearest Neighbors Classifier :',precision_score(y_test,y_pred_knn))\n",
    "print('recall score for K-Nearest Neighbors Classifier :',recall_score(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_svm=SVC(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(model_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy : 0.830056179775\n",
      "Best parameters:\n",
      " {'C': 1.5, 'degree': 1, 'gamma': 0.05, 'kernel': 'rbf'}\n",
      "Wall time: 15.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'C': [0.5,1,1.5,2], 'kernel': ['rbf'], 'gamma': [0.05,0.1,0.15],\n",
    "              'degree':[1,2,3]}\n",
    "grid_search = GridSearchCV(estimator = model_svm,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train_sc, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print('Best Accuracy :',best_accuracy)\n",
    "print('Best parameters:\\n',best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for SVM Classifier : 0.815642458101\n",
      "confusion matrix for SVM Classifier:\n",
      " [[100  10]\n",
      " [ 23  46]]\n",
      "F1 score for SVM Classifier : 0.736\n",
      "Precision score for SVM Classifier : 0.821428571429\n",
      "recall score for SVM Classifier : 0.666666666667\n",
      "Wall time: 103 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_svm=SVC(C=1.5,degree=1,gamma=0.05,kernel='rbf',random_state=0)\n",
    "model_svm.fit(X_train_sc,y_train)\n",
    "y_pred_svm=model_svm.predict(X_test_sc)\n",
    "print('accuracy for SVM Classifier :',accuracy_score(y_test,y_pred_svm))\n",
    "print('confusion matrix for SVM Classifier:\\n',confusion_matrix(y_test,y_pred_svm))\n",
    "print('F1 score for SVM Classifier :',f1_score(y_test,y_pred_svm))\n",
    "print('Precision score for SVM Classifier :',precision_score(y_test,y_pred_svm))\n",
    "print('recall score for SVM Classifier :',recall_score(y_test,y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_nb=GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for Naive Bayes Classifier : 0.798882681564\n",
      "confusion matrix for Naive Bayes Classifier:\n",
      " [[97 13]\n",
      " [23 46]]\n",
      "F1 score for Naive Bayes Classifier : 0.71875\n",
      "Precision score for Naive Bayes Classifier : 0.779661016949\n",
      "recall score for Naive Bayes Classifier : 0.666666666667\n",
      "Wall time: 29.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_nb.fit(X_train,y_train)\n",
    "y_pred_nb=model_nb.predict(X_test)\n",
    "print('accuracy for Naive Bayes Classifier :',accuracy_score(y_test,y_pred_nb))\n",
    "print('confusion matrix for Naive Bayes Classifier:\\n',confusion_matrix(y_test,y_pred_nb))\n",
    "print('F1 score for Naive Bayes Classifier :',f1_score(y_test,y_pred_nb))\n",
    "print('Precision score for Naive Bayes Classifier :',precision_score(y_test,y_pred_nb))\n",
    "print('recall score for Naive Bayes Classifier :',recall_score(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dt=DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(model_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy : 0.837078651685\n",
      "Best parameters:\n",
      " {'criterion': 'gini', 'max_depth': 3, 'min_impurity_decrease': 0, 'min_impurity_split': 0.2, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Wall time: 27.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'criterion': [\"gini\",\"entropy\"], 'max_depth': [3,5,7,10], 'min_samples_split': [2,5],\n",
    "              'min_samples_leaf':[1,2,3],'min_impurity_decrease':[0,0.1,0.2],'min_impurity_split':[0,0.05,0.1,0.2]}\n",
    "grid_search = GridSearchCV(estimator = model_dt,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print('Best Accuracy :',best_accuracy)\n",
    "print('Best parameters:\\n',best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for Decission Tree Classifier : 0.798882681564\n",
      "confusion matrix for Decission Tree Classifier:\n",
      " [[96 14]\n",
      " [22 47]]\n",
      "F1 score for Decission Tree Classifier : 0.723076923077\n",
      "Precision score for Decission Tree Classifier : 0.770491803279\n",
      "recall score for Decission Tree Classifier : 0.68115942029\n",
      "Wall time: 28 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_dt=DecisionTreeClassifier(criterion='gini',max_depth=6,random_state=0)\n",
    "model_dt.fit(X_train,y_train)\n",
    "y_pred_dt=model_dt.predict(X_test)\n",
    "print('accuracy for Decission Tree Classifier :',accuracy_score(y_test,y_pred_dt))\n",
    "print('confusion matrix for Decission Tree Classifier:\\n',confusion_matrix(y_test,y_pred_dt))\n",
    "print('F1 score for Decission Tree Classifier :',f1_score(y_test,y_pred_dt))\n",
    "print('Precision score for Decission Tree Classifier :',precision_score(y_test,y_pred_dt))\n",
    "print('recall score for Decission Tree Classifier :',recall_score(y_test,y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_rf=RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(model_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy : 0.838483146067\n",
      "Best parameters:\n",
      " {'criterion': 'gini', 'max_depth': 6, 'min_samples_leaf': 2, 'n_estimators': 100}\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'n_estimators':[100,200],'criterion':['entropy','gini'],\n",
    "              'min_samples_leaf':[2,5,7],\n",
    "              'max_depth':[5,6,7]\n",
    "               }\n",
    "grid_search = GridSearchCV(estimator = model_rf,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print('Best Accuracy :',best_accuracy)\n",
    "print('Best parameters:\\n',best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for Random Forest Classifier : 0.849162011173\n",
      "confusion matrix for Random Forest Classifier:\n",
      " [[101   9]\n",
      " [ 18  51]]\n",
      "F1 score for Random Forest Classifier : 0.790697674419\n",
      "Precision score for Random Forest Classifier : 0.85\n",
      "recall score for Random Forest Classifier : 0.739130434783\n",
      "Wall time: 638 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_rf=RandomForestClassifier(n_estimators=100,max_depth=6,criterion='entropy',min_samples_leaf=3,max_features=9,\n",
    "                                min_samples_split=2,min_impurity_decrease=0,random_state=0)\n",
    "model_rf.fit(X_train,y_train)\n",
    "y_pred_rf=model_rf.predict(X_test)\n",
    "print('accuracy for Random Forest Classifier :',accuracy_score(y_test,y_pred_rf))\n",
    "print('confusion matrix for Random Forest Classifier:\\n',confusion_matrix(y_test,y_pred_rf))\n",
    "print('F1 score for Random Forest Classifier :',f1_score(y_test,y_pred_rf))\n",
    "print('Precision score for Random Forest Classifier :',precision_score(y_test,y_pred_rf))\n",
    "print('recall score for Random Forest Classifier :',recall_score(y_test,y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_xgb=XGBClassifier(max_depth=3, learning_rate=0.1, n_estimators=100, silent=True, \n",
    "                        objective='binary:logistic', nthread=-1, gamma=0, min_child_weight=1, max_delta_step=0, \n",
    "                        subsample=1, colsample_bytree=1, colsample_bylevel=1, reg_alpha=0, reg_lambda=1, \n",
    "                        scale_pos_weight=1, base_score=0.5, seed=0, missing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for XGBoost Classifier : 0.860335195531\n",
      "confusion matrix for XGBoost Classifier:\n",
      " [[101   9]\n",
      " [ 16  53]]\n",
      "F1 score for XGBoost Classifier : 0.809160305344\n",
      "Precision score for XGBoost Classifier : 0.854838709677\n",
      "recall score for XGBoost Classifier : 0.768115942029\n",
      "Wall time: 492 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_xgb=XGBClassifier(max_depth=3, learning_rate=0.09, n_estimators=200, silent=True, \n",
    "                        objective='binary:logistic', nthread=-1, gamma=0, min_child_weight=1, max_delta_step=0, \n",
    "                        subsample=1, colsample_bytree=1, colsample_bylevel=1, reg_alpha=0, reg_lambda=1, \n",
    "                        scale_pos_weight=1, base_score=0.5, seed=0, missing=None)\n",
    "model_xgb.fit(X_train,y_train)\n",
    "y_pred_xgb=model_xgb.predict(X_test)\n",
    "print('accuracy for XGBoost Classifier :',accuracy_score(y_test,y_pred_xgb))\n",
    "print('confusion matrix for XGBoost Classifier:\\n',confusion_matrix(y_test,y_pred_xgb))\n",
    "print('F1 score for XGBoost Classifier :',f1_score(y_test,y_pred_xgb))\n",
    "print('Precision score for XGBoost Classifier :',precision_score(y_test,y_pred_xgb))\n",
    "print('recall score for XGBoost Classifier :',recall_score(y_test,y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating kaggle submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_submission_file(model, filename):\n",
    "    # converting to the matrix\n",
    "    test_X = X_test_processed\n",
    "    # make predictions\n",
    "    predictions = model.predict(test_X)\n",
    "    # submission dataframe\n",
    "    df_submission = pd.DataFrame({'PassengerId': test_processed.index, 'Survived' : predictions})\n",
    "    # submission file\n",
    "    submission_data_path = os.path.join('I:\\All_Projects\\DataSciencePluralsight','submission_file')\n",
    "    submission_file_path = os.path.join(submission_data_path, filename)\n",
    "    # write to the file\n",
    "    df_submission.to_csv(submission_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get submission file\n",
    "#get_submission_file(model_rf, 'byxgb2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 9. Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_ada=AdaBoostClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(model_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy : 0.828651685393\n",
      "Best parameters:\n",
      " {'algorithm': 'SAMME', 'learning_rate': 0.5, 'n_estimators': 200}\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parameters = {'n_estimators':[50,100,200],'learning_rate':[.4,.5,.6,.7],\n",
    "              'algorithm':['SAMME', 'SAMME.R']\n",
    "               }\n",
    "grid_search = GridSearchCV(estimator = model_ada,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print('Best Accuracy :',best_accuracy)\n",
    "print('Best parameters:\\n',best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg K-fold cross val score : 0.814653287475\n",
      "std of k-fold cross val score: \n",
      " 0.0244259736468\n",
      "accuracy for XGBoost Classifier : 0.826815642458\n",
      "confusion matrix for XGBoost Classifier:\n",
      " [[93 17]\n",
      " [14 55]]\n",
      "F1 score for XGBoost Classifier : 0.780141843972\n",
      "Precision score for XGBoost Classifier : 0.763888888889\n",
      "recall score for XGBoost Classifier : 0.797101449275\n",
      "Wall time: 4.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_ada=AdaBoostClassifier(algorithm='SAMME',learning_rate=1.3,n_estimators=200)\n",
    "model_ada.fit(X_train,y_train)\n",
    "y_pred_ada=model_ada.predict(X_test)\n",
    "kfscore=cross_val_score(estimator=model_ada,X=X_train,y=y_train,cv=3)\n",
    "Avg_kfscore=kfscore.mean()\n",
    "std_kfscore=kfscore.std()\n",
    "print('Avg K-fold cross val score :',Avg_kfscore)\n",
    "print('std of k-fold cross val score: \\n',std_kfscore)\n",
    "print('accuracy for AdaBoost Classifier :',accuracy_score(y_test,y_pred_ada))\n",
    "print('confusion matrix for AdaBoost Classifier:\\n',confusion_matrix(y_test,y_pred_ada))\n",
    "print('F1 score for AdaBoost Classifier :',f1_score(y_test,y_pred_ada))\n",
    "print('Precision score for AdaBoost Classifier :',precision_score(y_test,y_pred_ada))\n",
    "print('recall score for AdaBoost Classifier :',recall_score(y_test,y_pred_ada))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_bg=BaggingClassifier(random_state=0,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(model_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy : 0.801966292135\n",
      "Best parameters:\n",
      " {'n_estimators': 200, 'oob_score': True}\n",
      "Wall time: 29.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.7s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parameters = {'n_estimators':[10,50,100,200],\n",
    "              'oob_score':[True,False]\n",
    "               }\n",
    "grid_search = GridSearchCV(estimator = model_bg,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print('Best Accuracy :',best_accuracy)\n",
    "print('Best parameters:\\n',best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg K-fold cross val score : 0.810386601898\n",
      "std of k-fold cross val score: \n",
      " 0.00615924574837\n",
      "accuracy for Bagging Classifier : 0.815642458101\n",
      "confusion matrix for Bagging Classifier:\n",
      " [[98 12]\n",
      " [21 48]]\n",
      "F1 score for Bagging Classifier : 0.744186046512\n",
      "Precision score for Bagging Classifier : 0.8\n",
      "recall score for Bagging Classifier : 0.695652173913\n",
      "Wall time: 6.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_bg=BaggingClassifier(oob_score=True,n_estimators=200)\n",
    "model_bg.fit(X_train,y_train)\n",
    "y_pred_bg=model_bg.predict(X_test)\n",
    "kfscore=cross_val_score(estimator=model_bg,X=X_train,y=y_train,cv=3)\n",
    "Avg_kfscore=kfscore.mean()\n",
    "std_kfscore=kfscore.std()\n",
    "print('Avg K-fold cross val score :',Avg_kfscore)\n",
    "print('std of k-fold cross val score: \\n',std_kfscore)\n",
    "print('accuracy for Bagging Classifier :',accuracy_score(y_test,y_pred_bg))\n",
    "print('confusion matrix for Bagging Classifier:\\n',confusion_matrix(y_test,y_pred_bg))\n",
    "print('F1 score for Bagging Classifier :',f1_score(y_test,y_pred_bg))\n",
    "print('Precision score for Bagging Classifier :',precision_score(y_test,y_pred_bg))\n",
    "print('recall score for Bagging Classifier :',recall_score(y_test,y_pred_bg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Extra Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_et=ExtraTreesClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(model_et)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy : 0.830056179775\n",
      "Best parameters:\n",
      " {'criterion': 'entropy', 'max_depth': 7, 'n_estimators': 200}\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parameters = {'n_estimators':[10,50,100,200],\n",
    "              'criterion':[\"gini\",\"entropy\"],\n",
    "              'max_depth':[None,3,5,7,10]\n",
    "               }\n",
    "grid_search = GridSearchCV(estimator = model_et,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print('Best Accuracy :',best_accuracy)\n",
    "print('Best parameters:\\n',best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg K-fold cross val score : 0.804837546833\n",
      "std of k-fold cross val score: \n",
      " 0.03134840899\n",
      "accuracy for ExtraTrees Classifier : 0.798882681564\n",
      "confusion matrix for ExtraTrees Classifier:\n",
      " [[92 18]\n",
      " [18 51]]\n",
      "F1 score for ExtraTrees Classifier : 0.739130434783\n",
      "Precision score for ExtraTrees Classifier : 0.739130434783\n",
      "recall score for ExtraTrees Classifier : 0.739130434783\n",
      "Wall time: 1.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_et=ExtraTreesClassifier(criterion='gini',n_estimators=100,max_depth=3)\n",
    "model_et.fit(X_train,y_train)\n",
    "y_pred_et=model_et.predict(X_test)\n",
    "kfscore=cross_val_score(estimator=model_et,X=X_train,y=y_train,cv=3)\n",
    "Avg_kfscore=kfscore.mean()\n",
    "std_kfscore=kfscore.std()\n",
    "print('Avg K-fold cross val score :',Avg_kfscore)\n",
    "print('std of k-fold cross val score: \\n',std_kfscore)\n",
    "print('accuracy for ExtraTrees Classifier :',accuracy_score(y_test,y_pred_et))\n",
    "print('confusion matrix for ExtraTrees Classifier:\\n',confusion_matrix(y_test,y_pred_et))\n",
    "print('F1 score for ExtraTrees Classifier :',f1_score(y_test,y_pred_et))\n",
    "print('Precision score for ExtraTrees Classifier :',precision_score(y_test,y_pred_et))\n",
    "print('recall score for ExtraTrees Classifier :',recall_score(y_test,y_pred_et))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_gbc=GradientBoostingClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(model_gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy : 0.820224719101\n",
      "Best parameters:\n",
      " {'learning_rate': 0.5, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 100}\n",
      "Wall time: 2min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parameters = {'n_estimators':[100,200],'learning_rate':[0.5,0.7,1.0,1.2],\n",
    "              'loss':['deviance', 'exponential'],\n",
    "              'max_depth':[3,5,7]\n",
    "               }\n",
    "grid_search = GridSearchCV(estimator = model_gbc,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print('Best Accuracy :',best_accuracy)\n",
    "print('Best parameters:\\n',best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg K-fold cross val score : 0.794980439433\n",
      "std of k-fold cross val score: \n",
      " 0.0185166054631\n",
      "accuracy for GradientBoosting Classifier : 0.804469273743\n",
      "confusion matrix for GradientBoosting Classifier:\n",
      " [[94 16]\n",
      " [19 50]]\n",
      "F1 score for GradientBoosting Classifier : 0.740740740741\n",
      "Precision score for GradientBoosting Classifier : 0.757575757576\n",
      "recall score for GradientBoosting Classifier : 0.724637681159\n",
      "Wall time: 1.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_gbc=GradientBoostingClassifier(loss='exponential',learning_rate=0.5,n_estimators=100,max_depth=3)\n",
    "model_gbc.fit(X_train,y_train)\n",
    "y_pred_gbc=model_gbc.predict(X_test)\n",
    "kfscore=cross_val_score(estimator=model_gbc,X=X_train,y=y_train,cv=3)\n",
    "Avg_kfscore=kfscore.mean()\n",
    "std_kfscore=kfscore.std()\n",
    "print('Avg K-fold cross val score :',Avg_kfscore)\n",
    "print('std of k-fold cross val score: \\n',std_kfscore)\n",
    "print('accuracy for GradientBoosting Classifier :',accuracy_score(y_test,y_pred_gbc))\n",
    "print('confusion matrix for GradientBoosting Classifier:\\n',confusion_matrix(y_test,y_pred_gbc))\n",
    "print('F1 score for GradientBoosting Classifier :',f1_score(y_test,y_pred_gbc))\n",
    "print('Precision score for GradientBoosting Classifier :',precision_score(y_test,y_pred_gbc))\n",
    "print('recall score for GradientBoosting Classifier :',recall_score(y_test,y_pred_gbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting Training w/bin score mean: 93.05\n",
      "Hard Voting Test w/bin score mean: 82.73\n",
      "Hard Voting Test w/bin score 3*std: +/- 7.11\n",
      "----------\n",
      "Soft Voting Training w/bin score mean: 94.03\n",
      "Soft Voting Test w/bin score mean: 82.45\n",
      "Soft Voting Test w/bin score 3*std: +/- 6.76\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#why choose one model, when you can pick them all with voting classifier\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n",
    "#removed models w/o attribute 'predict_proba' required for vote classifier and models with a 1.0 correlation to another model\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import model_selection\n",
    "vote_est = [\n",
    "    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n",
    "    ('ada', ensemble.AdaBoostClassifier()),\n",
    "    ('bc', ensemble.BaggingClassifier()),\n",
    "    ('etc',ensemble.ExtraTreesClassifier()),\n",
    "    ('gbc', ensemble.GradientBoostingClassifier()),\n",
    "    ('rfc', ensemble.RandomForestClassifier()),\n",
    "\n",
    "    #Gaussian Processes: http://scikit-learn.org/stable/modules/gaussian_process.html#gaussian-process-classification-gpc\n",
    "    ('gpc', gaussian_process.GaussianProcessClassifier()),\n",
    "    \n",
    "    #GLM: http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "    ('lr', linear_model.LogisticRegressionCV()),\n",
    "    \n",
    "    #Navies Bayes: http://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "    ('bnb', naive_bayes.BernoulliNB()),\n",
    "    ('gnb', naive_bayes.GaussianNB()),\n",
    "    \n",
    "    #Nearest Neighbor: http://scikit-learn.org/stable/modules/neighbors.html\n",
    "    ('knn', neighbors.KNeighborsClassifier()),\n",
    "    \n",
    "    #SVM: http://scikit-learn.org/stable/modules/svm.html\n",
    "    ('svc', svm.SVC(probability=True)),\n",
    "    \n",
    "    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
    "   ('xgb', XGBClassifier())\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "#Hard Vote or majority rules\n",
    "vote_hard = ensemble.VotingClassifier(estimators = vote_est , voting = 'hard')\n",
    "vote_hard_cv = model_selection.cross_validate(vote_hard, X=X_train, y=y_train, cv  = 3)\n",
    "vote_hard.fit(X_train,y_train)\n",
    "\n",
    "print(\"Hard Voting Training w/bin score mean: {:.2f}\". format(vote_hard_cv['train_score'].mean()*100)) \n",
    "print(\"Hard Voting Test w/bin score mean: {:.2f}\". format(vote_hard_cv['test_score'].mean()*100))\n",
    "print(\"Hard Voting Test w/bin score 3*std: +/- {:.2f}\". format(vote_hard_cv['test_score'].std()*100*3))\n",
    "print('-'*10)\n",
    "\n",
    "\n",
    "#Soft Vote or weighted probabilities\n",
    "vote_soft = ensemble.VotingClassifier(estimators = vote_est , voting = 'soft')\n",
    "vote_soft_cv = model_selection.cross_validate(vote_soft, X_train,y_train, cv  = 3)\n",
    "vote_soft.fit(X_train,y_train)\n",
    "\n",
    "print(\"Soft Voting Training w/bin score mean: {:.2f}\". format(vote_soft_cv['train_score'].mean()*100)) \n",
    "print(\"Soft Voting Test w/bin score mean: {:.2f}\". format(vote_soft_cv['test_score'].mean()*100))\n",
    "print(\"Soft Voting Test w/bin score 3*std: +/- {:.2f}\". format(vote_soft_cv['test_score'].std()*100*3))\n",
    "print('-'*10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting Training w/bin score mean: 90.03\n",
      "Hard Voting Test w/bin score mean: 82.87\n",
      "Hard Voting Test w/bin score 3*std: +/- 5.76\n",
      "----------\n",
      "Soft Voting Training w/bin score mean: 91.43\n",
      "Soft Voting Test w/bin score mean: 82.59\n",
      "Soft Voting Test w/bin score 3*std: +/- 6.76\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#why choose one model, when you can pick them all with voting classifier\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n",
    "#removed models w/o attribute 'predict_proba' required for vote classifier and models with a 1.0 correlation to another model\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import model_selection\n",
    "vote_est = [\n",
    "    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n",
    "    ('ada', model_ada),\n",
    "    ('bc', model_bg),\n",
    "    ('etc',model_et),\n",
    "    ('gbc', model_gbc),\n",
    "    ('rfc', model_rf),\n",
    "\n",
    "        \n",
    "    #GLM: http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "    ('lr', model_lr),\n",
    "    \n",
    "    #Navies Bayes: http://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "    ('bnb', naive_bayes.BernoulliNB()),\n",
    "    ('gnb', model_nb),\n",
    "    \n",
    "    #Nearest Neighbor: http://scikit-learn.org/stable/modules/neighbors.html\n",
    "    ('knn', model_knn),\n",
    "    \n",
    "    #SVM: http://scikit-learn.org/stable/modules/svm.html\n",
    "    ('svc', svm.SVC(probability=True)),\n",
    "    \n",
    "    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
    "   ('xgb', model_xgb)\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "#Hard Vote or majority rules\n",
    "vote_hard = ensemble.VotingClassifier(estimators = vote_est , voting = 'hard')\n",
    "vote_hard_cv = model_selection.cross_validate(vote_hard, X=X_train, y=y_train, cv  = 3)\n",
    "vote_hard.fit(X_train,y_train)\n",
    "\n",
    "print(\"Hard Voting Training w/bin score mean: {:.2f}\". format(vote_hard_cv['train_score'].mean()*100)) \n",
    "print(\"Hard Voting Test w/bin score mean: {:.2f}\". format(vote_hard_cv['test_score'].mean()*100))\n",
    "print(\"Hard Voting Test w/bin score 3*std: +/- {:.2f}\". format(vote_hard_cv['test_score'].std()*100*3))\n",
    "print('-'*10)\n",
    "\n",
    "\n",
    "#Soft Vote or weighted probabilities\n",
    "vote_soft = ensemble.VotingClassifier(estimators = vote_est , voting = 'soft')\n",
    "vote_soft_cv = model_selection.cross_validate(vote_soft, X_train,y_train, cv  = 3)\n",
    "vote_soft.fit(X_train,y_train)\n",
    "\n",
    "print(\"Soft Voting Training w/bin score mean: {:.2f}\". format(vote_soft_cv['train_score'].mean()*100)) \n",
    "print(\"Soft Voting Test w/bin score mean: {:.2f}\". format(vote_soft_cv['test_score'].mean()*100))\n",
    "print(\"Soft Voting Test w/bin score 3*std: +/- {:.2f}\". format(vote_soft_cv['test_score'].std()*100*3))\n",
    "print('-'*10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get submission file\n",
    "get_submission_file(vote_soft, 'votesoft2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
